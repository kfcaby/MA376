---
title: "RedSox2018"
author: "Kevin Cummiskey"
date: "April 16, 2020"
output: pdf_document
---

# Chapter 6.1 Comparing Proportions - Are the Red Sox better at Fenway Park?

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE)
#library(tidyverse)
#library(knitr)
#redsox = read_csv(file = "Red Sox Season.csv")
#redsox = redsox %>% mutate(Result = factor(str_sub(`W/L`,start = 0, end = 1),
#                                           levels = c("W","L")))
#redsox = redsox %>% mutate(Field = case_when(is.na(X5) ~ "Home",
#                                                   TRUE ~ "Away"))
```

I'm a huge Boston Red Sox fan. Today we are going to investigate: *Are the Red Sox better at Fenway Park?*   

\includegraphics[height = 2in]{IMG_2128.jpeg}

## Background

The Major League Baseball season consists of 162 games.  Each team plays 81 games at home and 81 games on the road. The Red Sox play their home games at Fenway Park.

Let's consider the 2018 Red Sox (*why?*).  You can find more baseball data than you could ever analyze at www.retrosheet.org.  For today, we are going to use 2018 Retrosheet game logs.  This data set contains one row for each game (2,431 total) played in the 2018 season with over 150 variables recorded for each game.

## Get data from Retrosheet.org

If you want to follow along in R, go to https://www.retrosheet.org/gamelogs/index.html, download the 2018 file, unzip the file, and move it to your working directory in R. You can then run the code below.

```{r}
library(tidyverse)
library(knitr)

#---------------get retrosheet game log data---------------------#

website = "https://raw.githubusercontent.com/maxtoki/baseball_R/"
file = "master/data/game_log_header.csv"
glheaders <- read_csv(file = paste(website,file, sep = ""))
gamelogs2018 <- read_csv("GL2018.TXT",
                   col_names = names(glheaders),
                   na = character())

#Here is a small sample of the data.
gamelogs2018 %>% 
  select(Date, VisitingTeam, VisitorRunsScored, HomeTeam, HomeRunsScore) %>% 
  head(10) 
```

## Data Wrangling

Let's do a little data wrangling.

```{r}
#  Add a variable called WinningTeam.
gamelogs2018 %>% 
  mutate(WinningTeam = case_when(HomeRunsScore > VisitorRunsScored ~ 
                                   HomeTeam,
                                 VisitorRunsScored > HomeRunsScore ~
                                   VisitingTeam)) -> gamelogs2018

# Let's look at only games the Red Sox were involved in.
gamelogs2018 %>% 
  filter(HomeTeam == "BOS" | VisitingTeam == "BOS" ) -> redsox

# add Result (W/L) and Field (Home/Away) variables
redsox %>% 
  mutate(Result = ifelse(WinningTeam == "BOS", "W","L"),
         Field = ifelse(HomeTeam == "BOS", "Home", "Away"),
         RedSoxRunsScored = ifelse(HomeTeam == "BOS",
                                   HomeRunsScore,
                                   VisitorRunsScored),
         RedSoxStartingPitcherName = ifelse(HomeTeam == "BOS",
                                            HomeStartingPitcherName,
                                            VisitorStartingPitcherName)) -> redsox

# view sample of the redsox data frame.
redsox %>% 
  select(Date, VisitingTeam, VisitorRunsScored, HomeTeam, HomeRunsScore, Result, Field) %>% 
  head(10) %>% 
  kable(caption = "First 10 games of the Red Sox 2018 season")
```

## Study Design

Recall our research question: *Are the Red Sox better at Fenway Park?*  In other words, is there an association between playing at Fenway Park and the Red Sox winning?

What are the explanatory and response variables? Categorize each as categorical or quantitative.

\vspace{1in}

How does this study differ from simple linear regression and two-sample $t$-tests?

\vspace{1in}

```{r, message = F, result = 'asis'}
summary = redsox %>% 
  group_by(Field)%>% 
  count(Result) %>% 
  spread(key = Field, value = n)
kable(summary, caption = "Results of the Red Sox 2018 Season")
```


Calculate the \textit{conditional proportions} of wins for home games and away games. (You will also hear conditional proportions referred to as \textit{chances, likelihood, risk}).

\vspace{1in}

Calculate the \textit{odds} of winning at home and away. 

\vspace{1in}

Describe the relationship between odds and probabilty. The graph below might help.

\vspace{1in}

```{r, fig.height=2}
measures = data.frame(prob = seq(0,.90, by = 0.001))
measures = measures %>% mutate(odds = prob/(1-prob))
measures %>% ggplot(aes(x = prob, y = odds)) + 
  geom_line() +
  geom_line(aes(y = prob))
```

## Measures of Association

Next, we will calculate various measures of association between playing at Fenway Park and winning.  We will discuss four measures of association: *risk difference, relative risk, odds ratio, log odds ratio*.

* Calculate the difference in conditional proportions (also called \textit{risk difference}) comparing home games to away games.

\vspace{1in}

* Calculate the \textit{relative risk} for a win comparing home and away games. How does the risk difference and relative risk tell us something different?

\vspace{1in}

* Calculate the \textit{odds ratio} for wins comparing home and away games.  

\vspace{1in}

* Calculate the \textit{log odds ratio} for winning comparing home and away games. 

\vspace{1in}

For each measure of association above, describe the range of possible values.

* Risk difference

* Relative risk

* Odds ratio

* Log odds ratio

## Inference on Difference in Proportions

Write the null and alternative hypotheses for this test.

\vspace{1in}

What is the statistic of interest for this test?

\vspace{1in}

### Theory-based test (two sample z-test)

\[z = \frac{\hat{p}_1 - \hat{p_2}}{\sqrt{\hat{p}(1-\hat{p})\left(\frac{1}{n_1} + \frac{1}{n_2}\right)}}\]

Given a sufficiently large sample, $z$ is approximately standard normal under the null hypothesis.

<br />

```{r}
# two-sample z-test
phat_home = 57/81
phat_away = 51/81
phat = 108/162
#standardized statistic (pg 420)
z = (phat_home - phat_away)/sqrt(phat*(1-phat)*(1/81 + 1/81))
#p-value
2*(1-pnorm(z,0,1))
```

### Theory-based test ($\chi^2$ test)

Fill in the expected values in the table below if home/away has no effect and the Red Sox won 108 games. 

|Result | Away| Home| Total|
|:------|----:|----:|------|
|W      |     |     |   108|
|L      |     |     |    54|
|Total  |   81|   81|   182|

The $\chi^2$ test compares the observed counts in each cell to the expected counts.

\[ X^2 = \sum_{\text{all cells}} \frac{(\text{observed} - \text{expected})^2}{\text{expected}}\]

Calculate the $\chi^2$ statistic.

```{r}
#calculate overall win/loss percentage
summary_overall = redsox %>% group_by(Result) %>%
  count() %>% group_by() %>% mutate(perc = n/sum(n)) %>%
  select(-n)
#calculate expected wins
summary_homeaway = redsox %>% 
  group_by(Field,Result) %>%
  count() %>%
  left_join(summary_overall, by = "Result") %>%
  group_by(Field) %>%
  mutate(expected = perc*sum(n))
summary_homeaway  

#calculate chi-square statistic
chisq = summary_homeaway %>% group_by() %>%
  summarise(chisq = sum((n - expected)^2/expected))

1- pchisq(chisq$chisq, 1)
```

### Simulation-based test

Let's say I gave you 162 playing cards (one for each game) consisting of 81 red cards (home games) and 81 blue cards (away games).  Explain how you could conduct a simulation-based test with these cards.

\vspace{1in}

```{r, fig.height=3, cache = TRUE}
redsox.sim = redsox %>% select(Result, Field)
riskDiff.sim = c()
n.sims = 5000

for(i in 1:n.sims){
  summary.sim = redsox.sim %>% 
    mutate(Result.sim = sample(Result)) %>% #shuffle wins
    group_by(Field) %>%
    count(Result.sim) %>% mutate(p = n/sum(n)) #calculate win percentages
  riskDiff.sim[i] = summary.sim$p[3]-summary.sim$p[1]
}

hist(riskDiff.sim, breaks = 50)
sum(abs(riskDiff.sim) > (phat_home - phat_away))/n.sims
```

What would we conclude from these tests?

\vspace{1in}

Is confounding an issue in this analysis?  List variables that are potential confounding variables of the association between playing at Fenway Park and winning.

\vspace{1in}


## Intro to Logistic Regression

Here, we are going to repeat the analysis above using logistic regression.  For this case, the results will be the same (*why?*).  However, when we introduce more complex models, we cannot use the methods above -- we have to use logistic regression.

Let $Y_i$ be whether or not the Red Sox win game $i$ such that $Y_i \sim \text{Bernoulli}(\pi_i)$ be the probability the Red Sox win game $i$.

Here is our model:

\begin{equation}
\log\left(\frac{\pi_i}{1-\pi_i}\right) = \beta_0 + \beta_1 \text{Field}_i
\label{eq:model}
\end{equation}

where $\text{Field}_i$ is whether game $i$ was played on the home or away field.

Describe $\pi_i$ in words.

\vspace{1in}

Solve Equation \ref{eq:model} for $\pi_i$.

\vspace{1in}

What is another name for the left side of Equation \ref{eq:model}? 

\vspace{1in}

In regression models, we include a random error term ($\epsilon$) in the linear model.  Equation \ref{eq:model} does **not** have a random error term.  *Why?*

\vspace{1in}

According the the model, what are the log odds of the Red Sox winning on the road?

\vspace{1in}

According to the model, what are the log odds ofthe Red Sox winning at Fenway Park?

\vspace{1in}

How do we interpret $\beta_1$ in the model?

\vspace{1in}

What values of $\beta_1$ would indicate the Red Sox are more likely to win at Fenway Park then on the road?


```{r}
#reverse factor levels for result
#so win is 1 and loss is 0
redsox$Result = factor(redsox$Result,
                       levels = c("L","W"))
model_homeaway = glm(Result ~ Field, 
                     data = redsox, 
                     family = "binomial")
summary(model_homeaway)
```

Report estimates of the following:

* log odds ratio for winning comparing games at Fenway Park to road games.

* odds ratio for winning comparing games at Fenway Park to road games.

* probability of the Red Sox winning on the road.

* probability of the Red Sox winning at Fenway Park.

Have we seen these estimates before?

\vspace{1in}

What would we conclude from these results?

\vspace{1in}

## Runs Scored and Red Sox winning

In this section, we will investigate: *how does scoring affect the Red Sox's probability of winning?*.

What are the explanatory and response variables? Categorize each as categorical or quantitative.

\vspace{1in}

How does this study differ from the investigation of home/away and winning?

\vspace{1in}

Consider the following model: let $Y_i$ be whether or not the Red Sox win game $i$ such that $Y_i \sim \text{Bernoulli}(\pi_i)$ be the probability the Red Sox win game $i$.

Here is our model:

\begin{equation}
\log\left(\frac{\pi_i}{1-\pi_i}\right) = \beta_0 + \beta_1 \text{RunsScored}_i
\label{eq:modelRuns}
\end{equation}

where $\text{RunsScored}_i$ is the number of runs the Red Sox scored in game $i$.

According to the model, what are the log odds of a Red Sox win if they score 5 runs? 4 runs?

\vspace{1in}

According to the model, what is the probability the Red Sox win if they score 5 runs?

\vspace{1in}


How do we interpret $\beta_1$? $\beta_0$?

\vspace{1in}

Let's fit the model.

```{r}
#restrict analysis to between 1 and 10 runs scored
model.runsScored <- glm(Result == "W" ~ RedSoxRunsScored, 
                        family = "binomial",
                        data = redsox)
summary(model.runsScored)
```

Estimate the log odds of a Red Sox win if they score 5 runs? 4 runs?

\vspace{1in}

Estimate the probability the Red Sox win if they score 5 runs?

\vspace{1in}


```{r}
winProbs = tibble(RedSoxRunsScored = 0:15)
winProbs %>% mutate(pred.win.perc = predict(model.runsScored, 
                                          newdata = winProbs,
                                          type = "response")) -> winProbs
winProbs
```

What do we conclude based on this model?

\vspace{1in}

Let's investigate this model further.  This model says that the log odds of a Red Sox win are linear in Red Sox runs scored.  In other words, the log odds increase linearly with runs scored.  Let's see if that's actually the case in the data.


```{r, fig.height=3}
#calculate log odds by runs scored
redsox %>% 
  group_by(RedSoxRunsScored) %>% 
  summarize(Wins = sum(Result == "W"),
            Games = n()) %>% 
  mutate(perc = Wins/Games,
         logOdds = log(perc/(1 - perc))) -> runs.summary

runs.summary %>% head(10)

# a plot of the log odds
runs.summary %>% 
  ggplot(aes(x = RedSoxRunsScored,
             y = logOdds)) +
  geom_point() +
  labs(y = "log odds of a Red Sox win")
```

Is a linear model for the log odds appropriate?

\vspace{1in}

If the logs odds are linear in runs scored, are the odds linear in runs scored?

\vspace{1in}

## Which pitcher is most likely to result in a Red Sox win?

Let's look at the Red Sox record by starting pitcher.

```{r}
redsox %>% 
  group_by(RedSoxStartingPitcherName) %>% 
  summarize(W = sum(Result == "W"),
            L = sum(Result == "L"),
            Games = W + L,
            logOddsW = log(W/L),
            RunSupport = mean(RedSoxRunsScored)) %>% 
  arrange(-Games) -> redsox.bypitcher 
redsox.bypitcher %>%   
  kable(caption = "Results of Red Sox games by starting pitcher", digits = 1)
```

Why might we want to adjust for run support when assessing the relationship between pitcher and the Red Sox winning?

\vspace{1in}

Let's consider only pitchers with at least 20 starts. (*why?*)

```{r}
redsox.bypitcher %>% 
  filter(Games > 20 ) %>% 
  pull(RedSoxStartingPitcherName) -> redsox.20plusStarters

redsox.20plusStarters
```

Here is a model for pitcher and Red Sox winning adjusting for RunsScored.

\begin{equation}
\log\left(\frac{\pi_i}{1-\pi_i}\right) = \beta_0 + \beta_1 \text{RedSoxRunsScored}_i + \beta_2 \text{Price}_i + 
\beta_3 \text{Rodriguez}_i + \beta_4 \text{Porcello}_i
\label{eq:modelRuns}
\end{equation}

where $\text{RunsScored}_i$ is the number of runs the Red Sox scored in game $i$ and the other variables are whether or not that pitcher started the game.

```{r}
model.pitcher <- glm(Result == "W" ~ RedSoxRunsScored + RedSoxStartingPitcherName,
                     data = filter(redsox, RedSoxStartingPitcherName %in% redsox.20plusStarters),
                     family = "binomial")
summary(model.pitcher)
```

Calculate the probability the Red Sox win a game when they score 5 runs with Chris Sale pitching.

\vspace{1in}

What conclusions should we make from this output?

\vspace{1in}

Here are model predictions (win probabilities) for each pitcher by runs scored. (*why are they not linear?*)

```{r, fig.height=3}
runs = 1:10
tibble(expand_grid(runs,redsox.20plusStarters)) %>% 
  rename(RedSoxRunsScored = runs,
         RedSoxStartingPitcherName = redsox.20plusStarters) %>% 
  mutate(Win.prob = predict(model.pitcher, newdata = .,
                            type = "response")) -> predictions

predictions %>% 
  ggplot(aes(x = RedSoxRunsScored,
             y = Win.prob,
             color = RedSoxStartingPitcherName)) +
  geom_line()
```

How does a model with an interaction between RunsScored and pitcher change the interpretation?

\vspace{1in}

## Logistic Regression and Classification

A common application for logistic regression is to predict (or classify) a binary outcome.  In other words, based on some variables, we want to say whether the outcome will be a 1 or a 0, instead of merely reporting a probability.  For example, in the analyses above, we might want to predict whether the Red Sox will win (1) or lose (0) based on how many runs they scored and who was pitching. A common approach is to fit a logistic regression model, obtain predicted probabilities, and establish a cutoff probability.

Based on the model in the last section, would you classify a game that the Red Sox scored 3 runs and Chris Sale was pitching a win? What cutoff did you use?

\vspace{1in}

Ok, now let's do this for all games in 2018 with Porcello, Price, Rodriguez, or Sale starting and see how often our predictions are correct. To do this, we will obtain the *confusion matrix*.

```{r}
cutoff = 0.5
redsox %>% 
  filter(RedSoxStartingPitcherName %in% redsox.20plusStarters) %>% 
  mutate(Win.prob = predict(model.pitcher,
                            newdata = .,
                            type = "response"),
         Prediction = ifelse(Win.prob >= cutoff, "W","L")) %>% 
  select(HomeTeam, VisitingTeam, 
         RedSoxStartingPitcherName, 
         RedSoxRunsScored, Win.prob, 
         Prediction, Result) -> redsox.predictions

redsox.predictions %>% 
  select(-RedSoxStartingPitcherName) %>% 
  head(10)
```

The confusion matrix....

```{r}
redsox.predictions %>% 
  count(Result, Prediction) %>% 
  pivot_wider(values_from = n,
              names_from = Prediction)
```


What is the correct classification rate?

\vspace{1in}


```{r}
redsox.predictions %>% 
  ggplot(aes(x = RedSoxStartingPitcherName,
             y = Win.prob,
             color = Result)) +
  geom_point() +
  coord_flip() +
  geom_hline(yintercept = cutoff)
```


How could we improve this analysis with cross validation?





